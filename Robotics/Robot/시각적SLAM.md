# 시각적SLAM

> 상위: [[SLAM]]

카메라 센서를 이용하여 로봇의 위치 추정과 환경 지도 작성을 동시에 수행하는 기술입니다.

## 📷 센서 유형별 분류

### 단안 카메라 (Monocular)
- **장점**: 저비용, 소형, 경량
- **단점**: 스케일 모호성, 초기화 복잡
- **스케일 문제**: 실제 크기를 알 수 없음 (상대적 크기만)
- **해결방법**: IMU 융합, 알려진 물체 크기 활용

### 스테레오 카메라 (Stereo)
- **장점**: 직접적인 깊이 정보, 스케일 확정
- **단점**: 베이스라인 제약, 계산량 증가
- **시차 계산**: 좌우 영상의 대응점으로 깊이 추정
- **캘리브레이션**: 정확한 내외부 파라미터 필요

### RGB-D 카메라
- **장점**: 컬러 + 깊이 동시 제공, 조밀한 깊이맵
- **단점**: 실내 한정, 투명/반사 표면 취약
- **대표 센서**: Kinect, RealSense, Azure Kinect

## 🎯 핵심 구성요소

### 특징점 기반 방법
- **특징점 추출**: SIFT, SURF, ORB, FAST
- **서술자**: 특징점 주변의 외형 정보
- **매칭**: 연속 프레임간 대응점 찾기
- **이상치 제거**: RANSAC으로 잘못된 매칭 제거

### 직접법 (Direct Methods)
- **광도 일관성**: 픽셀 밝기 직접 비교
- **조밀한 추적**: 모든 픽셀 정보 활용
- **장점**: 텍스처 부족 환경에서도 동작
- **단점**: 조명 변화에 민감

### 반직접법 (Semi-Direct)
- **특징점 + 직접법**: 두 방법의 장점 결합
- **희소 특징점**: 키포인트에서만 직접법 적용
- **계산 효율**: 전체 영상 대신 선별된 점만 처리

## 🔄 Visual SLAM 파이프라인

### 1. 전처리 (Preprocessing)
- **왜곡 보정**: 렌즈 왜곡 제거
- **정규화**: 조명 변화 보상
- **노이즈 제거**: 가우시안 필터 등

### 2. 특징점 처리
- **추출**: 코너, 에지 등 특징점 검출
- **추적**: 연속 프레임에서 같은 점 추적
- **관리**: 새로운 특징점 추가, 오래된 점 제거

### 3. 포즈 추정
- **PnP**: 3D-2D 대응점으로 카메라 포즈 계산
- **에피폴라 기하**: 두 시점간의 기하학적 관계
- **번들 조정**: 여러 프레임의 포즈와 3D점 동시 최적화

### 4. 지도 관리
- **삼각측량**: 여러 시점에서 3D 점 생성
- **키프레임**: 중요한 프레임만 선별적 저장
- **루프 폐쇄**: 같은 장소 재방문 감지

## 🧮 수학적 기초

### 카메라 모델
```
핀홀 모델: [u, v, 1]^T = K × [X/Z, Y/Z, 1]^T
내부 파라미터 K: [fx  0  cx]
                  [0  fy  cy]
                  [0   0   1]
```

### 에피폴라 제약
```
기본 행렬: p2^T × F × p1 = 0
본질 행렬: E = [t]× × R
F = K2^(-T) × E × K1^(-1)
```

### 재투영 오차
```
오차 = ||p_observed - π(K × T × P)||²
최적화: minimize Σ재투영오차
```

## 🤖 대표적인 시스템

### ORB-SLAM
- **특징**: ORB 기반, 실시간 성능
- **구조**: 추적, 지역 매핑, 루프 폐쇄 스레드
- **장점**: 오픈소스, 높은 정확도
- **단점**: 텍스처 의존성

### DSO (Direct Sparse Odometry)
- **특징**: 직접법, 희소 추적
- **장점**: 텍스처 독립적, 빠른 속도
- **단점**: 루프 폐쇄 없음, 드리프트 누적

### PTAM/SLAM
- **특징**: 추적과 매핑 분리
- **장점**: 실시간 추적, 정확한 매핑
- **단점**: 작은 환경 한정

### LSD-SLAM
- **특징**: 직접법, 조밀한 재건
- **장점**: 전체 영상 활용, 조밀한 지도
- **단점**: 높은 계산량

## 💻 구현 및 도구

### ROS2 패키지
- **RTAB-Map**: RGB-D SLAM
- **ORB-SLAM3**: 최신 버전, 다중 센서 지원
- **VINS-Mono**: 시각-관성 SLAM

### 라이브러리
- **OpenCV**: 영상 처리, 특징점 추출
- **g2o**: 그래프 최적화
- **Ceres**: 비선형 최적화
- **Pangolin**: 3D 시각화

### 데이터셋
- **TUM RGB-D**: RGB-D 벤치마크
- **KITTI**: 자율주행 데이터
- **EuRoC**: 시각-관성 데이터

## ⚠️ 주요 도전과제

### 환경적 제약
- **조명 변화**: 그림자, 시간대 변화
- **텍스처 부족**: 흰 벽, 유리면
- **반복 패턴**: 잘못된 데이터 연관
- **동적 물체**: 움직이는 사람, 차량

### 기술적 한계
- **계산 복잡도**: 실시간 처리 요구
- **누적 오차**: 긴 궤적에서 드리프트
- **초기화**: 단안 카메라의 부트스트래핑
- **스케일 드리프트**: 단안에서 스케일 변화

## 🚀 최신 동향

### 딥러닝 융합
- **학습 기반 특징점**: SuperPoint, R2D2
- **깊이 추정**: 단안에서 학습 기반 깊이
- **의미론적 SLAM**: 물체 인식과 결합

### 강건성 향상
- **시각-관성 융합**: VIO (Visual-Inertial Odometry)
- **다중 센서**: 카메라 + 라이다 + IMU
- **전역 최적화**: 포즈 그래프 SLAM

## 🔗 연결 분야
- 상위: [[SLAM]]
- 센서: [[센서시스템]], [[환경인식]]
- 수학: [[영상처리]], [[컴퓨터비전]]
- 구현: [[ROS2]], [[OpenCV]]
- 응용: [[자율시스템응용]], [[서비스로봇]]