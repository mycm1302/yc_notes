# Iterative Learning Control (반복 학습 제어)

## 1. 개요 및 배경

Iterative Learning Control (ILC)은 동일한 작업을 반복적으로 수행하는 시스템에서 이전 시행의 경험을 바탕으로 다음 시행의 성능을 개선하는 제어 기법입니다. 1984년 Arimoto에 의해 최초로 제안되어, 반복적 작업이 많은 로봇 제어에서 중요한 역할을 하고 있습니다.

### 1.1 기본 개념

ILC의 핵심 아이디어:
1. **반복성**: 동일한 작업의 반복적 수행
2. **학습**: 이전 시행 오차 정보 활용
3. **개선**: 시행 횟수 증가에 따른 성능 향상
4. **완벽 추종**: 이론적으로 완벽한 추종 달성 가능

### 1.2 학습 철학

**인간의 학습 모방**: 
- 반복을 통한 기능 향상
- 경험 기반 개선
- 점진적 성능 향상

**제어 이론적 접근**:
- 시간 도메인과 시행 도메인의 이차원 시스템
- 수렴성 분석
- 강인성 보장

### 1.3 로봇 제어에서의 필요성

**반복 작업의 특성**:
- 조립 라인 작업
- Pick-and-place 작업
- 용접 및 페인팅
- 정밀 가공

**기존 제어의 한계**:
- 모델 불확실성
- 외란 및 마찰
- 반복 외란 (Repetitive Disturbance)
- 제한된 학습 능력

### 1.4 역사적 발전

- **1984년**: Arimoto의 최초 제안
- **1980년대 후반**: 기본 이론 확립
- **1990년대**: 강인성 및 수렴성 연구
- **2000년대**: 다차원 및 비선형 ILC 발전  
- **현재**: AI와 결합한 지능형 ILC 연구

## 2. 수학적 기초

### 2.1 시스템 모델

**시간-시행 이차원 시스템**:
- 시간 인덱스: t ∈ [0, T]
- 시행 인덱스: k = 0, 1, 2, ...

**선형 시스템**:
$$y_k(t) = P(s)u_k(t) + d_k(t)$$

여기서:
- yk(t): k번째 시행의 출력
- uk(t): k번째 시행의 제어 입력
- P(s): 시스템 전달함수
- dk(t): 반복 외란

**상태공간 형태**:
$$\dot{x}_k(t) = Ax_k(t) + Bu_k(t) + E d_k(t)$$
$$y_k(t) = Cx_k(t)$$

### 2.2 학습 법칙

**기본 P형 ILC**:
$$u_{k+1}(t) = u_k(t) + L \cdot e_k(t)$$

여기서:
- ek(t) = yd(t) - yk(t): 추종 오차
- L: 학습 이득
- yd(t): 원하는 궤적

**D형 ILC** (미분형):
$$u_{k+1}(t) = u_k(t) + L \cdot \dot{e}_k(t)$$

**PD형 ILC**:
$$u_{k+1}(t) = u_k(t) + L_P e_k(t) + L_D \dot{e}_k(t)$$

### 2.3 수렴 조건

**P형 ILC 수렴 조건**:
$$\|I - LP(j\omega)\| < 1, \quad \forall \omega$$

여기서 P(jω)는 시스템의 주파수 응답입니다.

**단조 수렴**: 
$$\|e_{k+1}(t)\| \leq \rho \|e_k(t)\|, \quad 0 < \rho < 1$$

**점대점 수렴**: 각 시간 점에서 독립적 수렴

### 2.4 리프팅 기법 (Lifting Technique)

**유한 시간 이산화**: t ∈ [0, T]를 N개 점으로 이산화

**리프트된 벡터**:
$$\mathbf{u}_k = \begin{bmatrix} u_k(0) \\ u_k(1) \\ \vdots \\ u_k(N-1) \end{bmatrix}, \quad \mathbf{y}_k = \begin{bmatrix} y_k(0) \\ y_k(1) \\ \vdots \\ y_k(N-1) \end{bmatrix}$$

**리프트된 시스템**:
$$\mathbf{y}_k = \mathbf{P}\mathbf{u}_k + \mathbf{d}_k$$

여기서 **P**는 하삼각 Toeplitz 행렬입니다.

## 3. ILC 설계 방법

### 3.1 주파수 영역 설계

**수렴 조건 분석**:
H(jω) = I - L(jω)P(jω)의 특이값 분석

**최적 학습 이득**:
$$L_{opt}(\omega) = \frac{P^*(\omega)}{|P(\omega)|^2 + \epsilon}$$

여기서 ε는 정규화 매개변수입니다.

**필터 설계**:
$$L(s) = L_0 \cdot Q(s)$$

Q(s): 저역통과 필터 (고주파 잡음 억제)

### 3.2 시간 영역 설계

**인과적 ILC**: 현재와 과거 정보만 사용
$$u_{k+1}(t) = u_k(t) + \int_0^t K(\tau) e_k(t-\tau) d\tau$$

**비인과적 ILC**: 전체 궤적 정보 사용
$$u_{k+1}(t) = u_k(t) + \int_0^T K(t,\tau) e_k(\tau) d\tau$$

### 3.3 강인 ILC

**모델 불확실성**: P(s) = P₀(s)(1 + Δ(s))

**강인성 조건**:
$$\|L(j\omega)\| \cdot |\Delta(j\omega)| < \frac{1 - \|I - L(j\omega)P_0(j\omega)\|}{|P_0(j\omega)|}$$

**H∞ ILC 설계**: 
최악의 경우 성능 보장

### 3.4 적응형 ILC

**시변 학습 이득**:
$$L_k = L_0 + \Delta L_k$$

**적응 법칙**:
$$\Delta L_{k+1} = \Delta L_k + \mu \mathbf{e}_k \mathbf{e}_k^T$$

## 4. 로봇 제어 응용

### 4.1 궤적 추종

**관절 공간 ILC**:
$$\boldsymbol{\tau}_{k+1}(t) = \boldsymbol{\tau}_k(t) + \mathbf{L} \mathbf{e}_k(t)$$

여기서 ek(t) = qd(t) - qk(t)

**작업 공간 ILC**:
엔드 이펙터 위치 오차 기반 학습

### 4.2 반복 외란 억제

**중력 보상 오차**: 부정확한 중력 모델
**마찰 보상**: 복잡한 마찰 특성
**백래시**: 기어 백래시 효과

**외란 학습**:
$$\hat{d}_{k+1}(t) = \hat{d}_k(t) + L_d e_k(t)$$

### 4.3 Pick-and-Place 작업

**반복성**: 동일한 위치 간 이동
**정밀성**: 높은 위치 정확도 요구
**속도**: 빠른 작업 수행

**성능 지표**:
- 위치 정확도: ±0.1mm
- 반복 정밀도: ±0.01mm  
- 사이클 타임: 최소화
