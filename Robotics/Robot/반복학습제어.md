# Iterative Learning Control (반복학습제어)

## 1. 개요 및 배경

반복학습제어(ILC)는 반복적으로 수행되는 작업에서 이전 시행의 오차 정보를 활용하여 제어 성능을 점진적으로 개선하는 제어 기법입니다. 1984년 일본의 Arimoto에 의해 처음 제안되었으며, "Practice makes perfect"라는 인간의 학습 원리를 제어 시스템에 적용한 혁신적인 접근법입니다.

### 1.1 기본 개념

반복학습제어의 핵심 아이디어:
1. **반복 작업**: 동일한 궤적을 반복적으로 수행
2. **오차 기억**: 이전 시행의 오차 정보 저장
3. **점진적 개선**: 시행 횟수에 따른 성능 향상
4. **모델 독립성**: 정확한 시스템 모델 불필요

### 1.2 학습 원리

**인간의 학습과 유사성**:
- 연습을 통한 기능 향상
- 실수로부터의 학습
- 점진적 완벽화 과정

**제어 관점**:
$$u_k(t) = u_{k-1}(t) + \Delta u_k(t)$$

여기서:
- k: 시행 번호 (trial number)
- t: 시간
- Δu_k(t): k번째 시행에서의 제어 수정량

### 1.3 적용 조건

**필수 조건**:
1. **반복성**: 동일한 작업의 반복 수행
2. **초기화**: 매 시행마다 동일한 초기 조건
3. **유한 시간**: 제한된 시간 구간 [0, T]
4. **재현성**: 반복 가능한 시스템 특성

### 1.4 로봇 제어에서의 중요성

- **반복 작업**: 제조업 로봇의 반복적 동작
- **정밀도 향상**: 시행을 통한 추종 정확도 개선
- **적응성**: 환경 변화에 대한 자동 적응
- **모델 프리**: 복잡한 모델링 없이 성능 향상
## 2. 수학적 기초

### 2.1 시스템 모델

**일반 선형 시스템**:
$$\begin{align}
\dot{x}_k(t) &= Ax_k(t) + Bu_k(t) \\
y_k(t) &= Cx_k(t)
\end{align}$$

**초기 조건**: $x_k(0) = x_0$ (모든 k에 대해 동일)

**비선형 시스템**:
$$\begin{align}
\dot{x}_k(t) &= f(x_k(t), u_k(t), t) \\
y_k(t) &= g(x_k(t), t)
\end{align}$$

### 2.2 오차 정의

**추종 오차**:
$$e_k(t) = y_d(t) - y_k(t)$$

**입력 수정량**:
$$\Delta u_k(t) = u_k(t) - u_{k-1}(t)$$

**오차 진화**:
$$e_{k+1}(t) = e_k(t) - \Delta e_k(t)$$

### 2.3 기본 학습 법칙

**D-형 학습 법칙** (Derivative-type):
$$u_{k+1}(t) = u_k(t) + L\dot{e}_k(t)$$

**P-형 학습 법칙** (Proportional-type):
$$u_{k+1}(t) = u_k(t) + \Gamma e_k(t)$$

**PD-형 학습 법칙**:
$$u_{k+1}(t) = u_k(t) + \Gamma_P e_k(t) + \Gamma_D \dot{e}_k(t)$$

여기서 L, Γ_P, Γ_D는 학습 이득 행렬입니다.
### 2.4 수렴성 분석

**람다 규범 (λ-norm)**:
임의의 함수 f(t)에 대해:
$$\|f\|_\lambda = \sup_{t \in [0,T]} |f(t)|e^{-\lambda t}$$

**수렴 조건** (선형 시스템):
D-형 학습에서 다음 조건이 만족되면 수렴:
$$\|I - LCB\|_\lambda < 1$$

여기서:
- I: 단위 행렬
- L: 학습 이득
- C, B: 시스템 행렬

**Arimoto의 조건**:
$$\rho = \|I - \Gamma CB\| < 1$$

여기서 ρ는 스펙트럼 반경(spectral radius)입니다.

### 2.5 주파수 영역 분석

**전달 함수 접근**:
시스템 전달 함수 G(s)에 대해:
$$E_{k+1}(s) = (I - L(s)G(s))E_k(s)$$

**수렴 조건**:
$$\|I - L(s)G(s)\|_\infty < 1, \quad \forall s$$

**Nyquist 판정법**: 
L(jω)G(jω)의 Nyquist 선도가 (1,0) 점을 중심으로 하는 단위원 내부에 위치

### 2.6 비선형 시스템

**수축 사상 (Contraction Mapping)**:
학습 연산자 T가 수축 사상이면 수렴:
$$\|T(u_1) - T(u_2)\| \leq \rho \|u_1 - u_2\|, \quad \rho < 1$$

**Lipschitz 조건**:
$$\|f(x_1, u, t) - f(x_2, u, t)\| \leq L_f \|x_1 - x_2\|$$
## 3. 로봇 제어 적용

### 3.1 로봇 매니퓰레이터

**로봇 동역학**:
$$M(q)\ddot{q} + C(q,\dot{q})\dot{q} + G(q) = \tau$$

**반복 학습 구조**:
$$\tau_{k+1}(t) = \tau_k(t) + \Gamma_P e_k(t) + \Gamma_D \dot{e}_k(t)$$

**위치 오차**:
$$e_k(t) = q_d(t) - q_k(t)$$

### 3.2 복합 제어 구조

**기본 피드백 + ILC**:
$$\tau_k(t) = \tau_{ff,k}(t) + K_P(q_d(t) - q_k(t)) + K_D(\dot{q}_d(t) - \dot{q}_k(t))$$

**학습 법칙**:
$$\tau_{ff,k+1}(t) = \tau_{ff,k}(t) + L e_k(t)$$

**장점**:
- 기본 안정성: 피드백 제어기
- 성능 향상: 반복 학습
- 점진적 개선: 피드포워드 항 학습

### 3.3 작업 공간 ILC

**작업 공간 오차**:
$$e_{x,k}(t) = x_d(t) - x_k(t)$$

**관절 공간 변환**:
$$e_{q,k}(t) = J^T(q_k(t)) e_{x,k}(t)$$

**학습 법칙**:
$$\tau_{k+1}(t) = \tau_k(t) + \Gamma J^T(q_d(t)) e_{x,k}(t)$$

### 3.4 궤적 학습

**시간 매개변수 궤적**:
$$q_d(t) = [q_{d1}(t), q_{d2}(t), \ldots, q_{dn}(t)]^T$$

**매개변수 학습**:
궤적을 기저 함수의 선형 결합으로 표현:
$$q_d(t) = \sum_{i=1}^N a_i \phi_i(t)$$

**매개변수 갱신**:
$$a_{i,k+1} = a_{i,k} + \gamma_i \int_0^T \phi_i(t) e_k(t) dt$$
## 4. 고급 ILC 기법

### 4.1 적응형 ILC

**시간 가변 이득**:
$$L_k(t) = L_0 + \alpha_k(t) \Delta L$$

**적응 법칙**:
$$\alpha_{k+1}(t) = \alpha_k(t) + \beta \text{sign}(e_k(t)) \text{sign}(\dot{e}_k(t))$$

**이득 조정 기준**:
- 오차 크기에 따른 적응적 조정
- 수렴 속도 최적화
- 강인성 향상

### 4.2 강인 ILC

**불확실성 고려**:
시스템에 불확실성 Δ가 존재하는 경우:
$$\dot{x}_k = (A + \Delta A)x_k + (B + \Delta B)u_k$$

**강인 학습 법칙**:
$$u_{k+1}(t) = u_k(t) + L e_k(t) + \mu_k(t) \text{sign}(e_k(t))$$

**μ_k(t) 선택 기준**:
$$\mu_k(t) \geq \|\Delta A x_k(t) + \Delta B u_k(t)\|$$

### 4.3 고차 ILC

**2차 학습 법칙**:
$$u_{k+1}(t) = u_k(t) + \Gamma_1 e_k(t) + \Gamma_2 e_{k-1}(t)$$

**일반 고차 형태**:
$$u_{k+1}(t) = \sum_{i=0}^p \alpha_i u_{k-i}(t) + \sum_{j=0}^q \beta_j e_{k-j}(t)$$

**안정성 조건**:
특성 방정식의 근이 단위원 내부에 위치:
$$\sum_{i=0}^p \alpha_i z^{-i} = 0$$

### 4.4 예측형 ILC

**미래 오차 예측**:
$$\hat{e}_{k+1}(t) = e_k(t) - G(s) \Delta u_{k+1}(t)$$

**예측 기반 학습**:
$$u_{k+1}(t) = u_k(t) + L[\hat{e}_{k+1}(t)]$$

**모델 예측 ILC**:
미래 여러 시점의 오차를 고려한 최적화:
$$\min_{\Delta u} \sum_{i=1}^N \|\hat{e}_{k+1}(t+i)\|^2 + \lambda \|\Delta u_k(t)\|^2$$
## 5. 실제 응용 사례

### 5.1 산업용 로봇

**점 용접 로봇**:
- 반복적인 용접점 작업
- 높은 위치 정확도 요구
- 열변형에 의한 오차 보상

**도장 로봇**:
- 복잡한 3차원 궤적
- 균일한 도장 두께 제어
- 환경 변화 적응

**조립 로봇**:
- 정밀한 삽입 작업
- 힘/위치 복합 제어
- 부품 공차 보상

### 5.2 CNC 머시닝

**윤곽 가공**:
$$\tau_{k+1}(t) = \tau_k(t) + L_p e_{pos,k}(t) + L_v e_{vel,k}(t)$$

**표면 조도 개선**:
- 반복적인 가공 패스
- 절삭력 변동 학습
- 공구 마모 보상

### 5.3 의료용 로봇

**수술 로봇**:
- 미세한 동작 제어
- 생체 조직의 비선형성
- 안전성 최우선

**재활 로봇**:
- 환자별 맞춤 훈련
- 점진적 난이도 증가
- 운동 패턴 학습

### 5.4 이동 로봇

**경로 추종**:
$$e_{k+1}(t) = [I - G(s)L(s)]e_k(t)$$

**장애물 회피 학습**:
- 동적 환경 적응
- 최적 경로 탐색
- 안전 마진 유지
## 6. 설계 고려사항

### 6.1 학습 이득 선택

**안정성 조건**:
$$\sigma_{\max}(I - LG) < 1$$

**이득 튜닝 가이드라인**:
- 작은 이득: 느린 수렴, 높은 안정성
- 큰 이득: 빠른 수렴, 불안정 위험
- 주파수별 조정: 고주파수 억제

**실용적 선택법**:
$$L = \beta G^T(G G^T + \alpha I)^{-1}$$

여기서 α는 정규화 매개변수, β는 수렴 조정 매개변수

### 6.2 노이즈 대응

**측정 노이즈**:
$$y_k(t) = y_{true}(t) + n_k(t)$$

**필터링 방법**:
- 저역 통과 필터
- 칼만 필터
- 웨이블릿 기반 노이즈 제거

**강인 학습 법칙**:
$$u_{k+1}(t) = u_k(t) + L Q(s) e_k(t)$$

여기서 Q(s)는 저역 통과 필터

### 6.3 초기화 전략

**동일 초기 조건**: 필수 요구사항
$$x_k(0) = x_0, \quad \forall k$$

**초기 입력 선택**:
- 제로 입력: $u_0(t) = 0$
- 사전 설계: 피드백 제어기 출력
- 모델 기반: 역동역학 계산
## 7. 장단점 분석

### 7.1 장점

1. **모델 독립성**: 정확한 시스템 모델 불필요
2. **점진적 개선**: 시행 횟수에 따른 성능 향상
3. **단순성**: 비교적 간단한 구현
4. **효과성**: 반복 작업에서 탁월한 성능
5. **범용성**: 다양한 시스템에 적용 가능
6. **외란 학습**: 반복적 외란에 대한 자동 보상

### 7.2 단점

1. **반복성 요구**: 동일 작업만 적용 가능
2. **수렴 속도**: 충분한 학습을 위한 다수 시행 필요
3. **메모리 요구**: 이전 시행 데이터 저장 필요
4. **초기화 조건**: 정확한 초기 조건 재현 필수
5. **노이즈 민감성**: 측정 노이즈에 대한 민감성
6. **실시간 제한**: 온라인 학습의 어려움

### 7.3 다른 제어 기법과의 비교

**vs 적응 제어**:
- ILC: 시행 간 학습, 반복 작업에 특화
- 적응 제어: 실시간 적응, 매개변수 변화 대응

**vs 강인 제어**:
- ILC: 특정 외란 패턴 학습
- 강인 제어: 광범위한 불확실성 대응

**vs 최적 제어**:
- ILC: 모델 프리 접근
- 최적 제어: 정확한 모델 기반 최적화

### 7.4 실용성 평가

**제조업 적용**: 매우 높음
- 반복적 제조 공정
- 높은 정밀도 요구
- 설정 시간 여유

**서비스 로봇**: 제한적
- 다양한 작업 환경
- 일회성 작업 많음
- 실시간 반응 필요
## 8. 최신 동향

### 8.1 딥러닝 기반 ILC

**신경망 학습 법칙**:
$$u_{k+1}(t) = u_k(t) + \text{NN}(e_k(t), \dot{e}_k(t), t)$$

**장점**:
- 복잡한 비선형 관계 학습
- 자동 특징 추출
- 적응적 이득 조정

**연구 동향**:
- CNN을 이용한 공간적 패턴 학습
- RNN을 이용한 시간적 의존성 활용
- 강화학습과의 결합

### 8.2 분산 ILC

**다중 에이전트 시스템**:
$$u_{i,k+1}(t) = u_{i,k}(t) + L_i e_{i,k}(t) + \sum_{j \in N_i} w_{ij} [u_{j,k}(t) - u_{i,k}(t)]$$

**협조적 학습**:
- 에이전트 간 정보 공유
- 통신 지연 고려
- 분산 최적화

### 8.3 확률적 ILC

**불확실성 고려**:
시스템 매개변수가 확률 분포를 따르는 경우:
$$\theta \sim \mathcal{N}(\mu_\theta, \Sigma_\theta)$$

**베이지안 ILC**:
- 매개변수 불확실성 모델링
- 확률적 성능 지표
- 위험 인식 학습

### 8.4 이벤트 기반 ILC

**이벤트 트리거 조건**:
$$\|e_k(t)\| > \delta$$

**장점**:
- 통신 부하 감소
- 에너지 효율성
- 선택적 학습

### 8.5 데이터 기반 ILC

**모델 프리 접근**:
- 시스템 식별 없이 직접 학습
- 빅데이터 활용
- 클라우드 기반 협조 학습

**전이 학습**:
- 다른 시스템에서의 경험 활용
- 도메인 적응
- 메타 학습
## 9. 관련 텍스트북 및 참고문헌

### 주요 텍스트북

1. **Bristow, D. A., Tharayil, M., & Alleyne, A. G. (2006)**. "A Survey of Iterative Learning Control". IEEE Control Systems Magazine.
   - ILC의 포괄적 리뷰
   - 이론부터 응용까지 체계적 정리

2. **Ahn, H.-S., Chen, Y., & Moore, K. L. (2007)**. "Iterative Learning Control: Brief Survey and Categorization". IEEE Transactions on Systems, Man, and Cybernetics.
   - ILC 분류 체계
   - 다양한 변형 기법들

3. **Xu, J.-X., & Tan, Y. (2003)**. "Linear and Nonlinear Iterative Learning Control". Springer-Verlag.
   - 선형 및 비선형 ILC 이론
   - 수학적 기초부터 응용까지

4. **Moore, K. L. (1993)**. "Iterative Learning Control for Deterministic Systems". Springer-Verlag.
   - ILC의 고전적 명저
   - 결정론적 시스템에 대한 체계적 접근

### 중요 논문들

1. **Arimoto, S., Kawamura, S., & Miyazaki, F. (1984)**. "Bettering Operation of Robots by Learning". Journal of Robotic Systems.
   - ILC의 원조 논문
   - "Practice makes perfect" 개념 도입

2. **Craig, J. J. (1984)**. "Adaptive Control of Manipulators through Repeated Trials". Proceedings of American Control Conference.
   - 로봇 매니퓰레이터에 대한 초기 적용
   - 적응 제어와의 차별화

3. **Moore, K. L., & Xu, J.-X. (2000)**. "Editorial: Special Issue on Iterative Learning Control". International Journal of Control.
   - ILC 연구 동향 정리
   - 주요 연구 방향 제시

4. **Norrlöf, M., & Gunnarsson, S. (2002)**. "Time and Frequency Domain Convergence Properties in Iterative Learning Control". International Journal of Control.
   - 수렴성 분석의 고전
   - 시간 및 주파수 영역 접근

### 로봇 응용 논문들

- **Bien, Z., & Xu, J.-X. (Eds.) (1998)**. "Iterative Learning Control: Analysis, Design, Integration and Applications". Kluwer Academic Publishers.

- **Lee, J. H., Lee, K. S., & Kim, W. C. (2000)**. "Model-based Iterative Learning Control with a Quadratic Criterion for Time-varying Linear Systems". Automatica.

- **Tayebi, A., & Zaremba, M. B. (2003)**. "Robust Iterative Learning Control Design is Straightforward for Uncertain LTI Systems". IEEE Transactions on Automatic Control.

### 최신 연구 동향

- **Chi, R., Hou, Z., & Xu, J. (2008)**. "Adaptive ILC for a Class of Discrete-time Systems with Iteration-varying Trajectory and Random Initial Condition". Automatica.

- **Shen, D., & Wang, Y. (2014)**. "Survey on Stochastic Iterative Learning Control". Journal of Process Control.

- **van de Wijdeven, J., & Bosgra, O. (2010)**. "Using Basis Functions in Iterative Learning Control: Analysis and Design Theory". International Journal of Control.

### 미분 기하학 및 학습 이론

**수학적 배경**:
- **Ljung, L. (1999)**. "System Identification: Theory for the User". Prentice Hall.
- **Goodwin, G. C., & Sin, K. S. (1984)**. "Adaptive Filtering, Prediction and Control". Prentice Hall.

이 문서는 Arimoto의 원조 논문과 Bristow et al.의 서베이 논문을 주요 참고문헌으로 하여 작성되었습니다.