# Optimal Control (최적 제어)

## 1. 개요 및 배경

Optimal Control은 주어진 성능 지표를 최적화하는 제어 입력을 찾는 이론과 방법론입니다. 1950년대 Bellman의 동적 계획법과 Pontryagin의 최대 원리에서 시작되어, 현재 로봇 제어에서 궤적 최적화, 에너지 효율성, 시간 최적화 등에 광범위하게 사용되고 있습니다.

### 1.1 기본 개념

최적 제어의 핵심 아이디어:
1. **성능 지표**: 최적화하고자 하는 목적 함수 정의
2. **제약 조건**: 시스템 동역학과 물리적 제약
3. **변분법**: 함수의 최적화를 위한 수학적 도구
4. **필요 조건**: 최적해가 만족해야 하는 조건

### 1.2 최적 제어 문제의 일반 형태

**목적 함수**:
$$J = \phi(\mathbf{x}(t_f), t_f) + \int_{t_0}^{t_f} L(\mathbf{x}(t), \mathbf{u}(t), t) dt$$

**제약 조건**:
- 동역학: $\dot{\mathbf{x}}(t) = \mathbf{f}(\mathbf{x}(t), \mathbf{u}(t), t)$
- 초기 조건: $\mathbf{x}(t_0) = \mathbf{x}_0$
- 경계 조건: $\boldsymbol{\psi}(\mathbf{x}(t_f), t_f) = \mathbf{0}$
- 경로 제약: $\mathbf{g}(\mathbf{x}(t), \mathbf{u}(t), t) \leq \mathbf{0}$

여기서:
- x(t): 상태 벡터
- u(t): 제어 입력
- φ(·): 종단 비용
- L(·): 러닝 비용

### 1.3 로봇 제어에서의 응용

**궤적 최적화**:
- 최소 시간 궤적
- 최소 에너지 궤적
- 최소 저크 궤적

**제어 최적화**:
- LQR (Linear Quadratic Regulator)
- LQG (Linear Quadratic Gaussian)
- 비선형 최적 제어

**경로 계획**:
- 장애물 회피
- 다중 목표 최적화
- 강인 경로 계획

## 2. 수학적 기초

### 2.1 변분법 (Calculus of Variations)

**오일러-라그랑주 방정식**:
함수 $y(x)$에 대한 범함수 $J[y] = \int_{x_0}^{x_1} F(x, y, y') dx$의 최적화

$$\frac{d}{dx}\left(\frac{\partial F}{\partial y'}\right) - \frac{\partial F}{\partial y} = 0$$

**제약이 있는 변분 문제**:
라그랑주 승수법을 이용한 등제약 조건 처리

### 2.2 Pontryagin의 최대 원리

**해밀토니안**:
$$H(\mathbf{x}, \mathbf{u}, \boldsymbol{\lambda}, t) = L(\mathbf{x}, \mathbf{u}, t) + \boldsymbol{\lambda}^T \mathbf{f}(\mathbf{x}, \mathbf{u}, t)$$

**필요 조건**:
1. **상태 방정식**: $\dot{\mathbf{x}} = \frac{\partial H}{\partial \boldsymbol{\lambda}} = \mathbf{f}(\mathbf{x}, \mathbf{u}, t)$
2. **공상태 방정식**: $\dot{\boldsymbol{\lambda}} = -\frac{\partial H}{\partial \mathbf{x}}$
3. **최적성 조건**: $\frac{\partial H}{\partial \mathbf{u}} = \mathbf{0}$ (제약 없는 경우)
4. **횡단성 조건**: 경계에서의 조건

**최대 원리**: 최적 제어 u*(t)에 대해
$$H(\mathbf{x}^*, \mathbf{u}^*, \boldsymbol{\lambda}^*, t) = \max_{\mathbf{u} \in \mathcal{U}} H(\mathbf{x}^*, \mathbf{u}, \boldsymbol{\lambda}^*, t)$$

### 2.3 동적 계획법 (Dynamic Programming)

**Bellman의 최적성 원리**:
최적 정책의 부분도 최적

**해밀턴-야코비-벨만 방정식**:
$$-\frac{\partial V}{\partial t} = \min_{\mathbf{u}} \left[ L(\mathbf{x}, \mathbf{u}, t) + \left(\frac{\partial V}{\partial \mathbf{x}}\right)^T \mathbf{f}(\mathbf{x}, \mathbf{u}, t) \right]$$

여기서 V(x,t)는 가치 함수입니다.

**경계 조건**: $V(\mathbf{x}, t_f) = \phi(\mathbf{x}, t_f)$

**최적 제어**: $\mathbf{u}^*(\mathbf{x}, t) = \arg\min_{\mathbf{u}} \left[ L(\mathbf{x}, \mathbf{u}, t) + \left(\frac{\partial V}{\partial \mathbf{x}}\right)^T \mathbf{f}(\mathbf{x}, \mathbf{u}, t) \right]$

## 3. 선형 최적 제어

### 3.1 LQR (Linear Quadratic Regulator)

**시스템**: $\dot{\mathbf{x}} = \mathbf{A}\mathbf{x} + \mathbf{B}\mathbf{u}$

**비용 함수**:
$$J = \frac{1}{2}\mathbf{x}^T(t_f)\mathbf{S}\mathbf{x}(t_f) + \frac{1}{2}\int_{t_0}^{t_f} [\mathbf{x}^T\mathbf{Q}\mathbf{x} + \mathbf{u}^T\mathbf{R}\mathbf{u}] dt$$

**리카티 방정식**:
$$-\dot{\mathbf{P}} = \mathbf{A}^T\mathbf{P} + \mathbf{P}\mathbf{A} - \mathbf{P}\mathbf{B}\mathbf{R}^{-1}\mathbf{B}^T\mathbf{P} + \mathbf{Q}$$

**경계 조건**: $\mathbf{P}(t_f) = \mathbf{S}$

**최적 제어**:
$$\mathbf{u}^*(t) = -\mathbf{R}^{-1}\mathbf{B}^T\mathbf{P}(t)\mathbf{x}(t) = -\mathbf{K}(t)\mathbf{x}(t)$$

**무한 지평선 LQR**:
대수 리카티 방정식 (ARE):
$$\mathbf{A}^T\mathbf{P} + \mathbf{P}\mathbf{A} - \mathbf{P}\mathbf{B}\mathbf{R}^{-1}\mathbf{B}^T\mathbf{P} + \mathbf{Q} = \mathbf{0}$$

### 3.2 LQG (Linear Quadratic Gaussian)

**확률적 시스템**:
$$d\mathbf{x} = \mathbf{A}\mathbf{x}dt + \mathbf{B}\mathbf{u}dt + d\mathbf{w}$$
$$\mathbf{y} = \mathbf{C}\mathbf{x} + \mathbf{v}$$

여기서 w, v는 가우시안 잡음입니다.

**분리 원리**: 제어와 추정 문제를 독립적으로 해결
1. 칼만 필터로 상태 추정
2. LQR로 제어기 설계

**칼만 필터**:
$$\dot{\hat{\mathbf{x}}} = \mathbf{A}\hat{\mathbf{x}} + \mathbf{B}\mathbf{u} + \mathbf{L}(\mathbf{y} - \mathbf{C}\hat{\mathbf{x}})$$

**칼만 이득**: $\mathbf{L} = \mathbf{P}_e\mathbf{C}^T\mathbf{R}_v^{-1}$

### 3.3 로봇에서의 LQR 응용

**선형화된 로봇 동역학**:
$$\begin{bmatrix} \dot{\mathbf{q}} \\ \ddot{\mathbf{q}} \end{bmatrix} = \begin{bmatrix} \mathbf{0} & \mathbf{I} \\ \mathbf{0} & \mathbf{0} \end{bmatrix} \begin{bmatrix} \mathbf{q} \\ \dot{\mathbf{q}} \end{bmatrix} + \begin{bmatrix} \mathbf{0} \\ \mathbf{M}^{-1} \end{bmatrix} \boldsymbol{\tau}$$

**가중 행렬 설계**:
- Q: 상태 오차 가중 (위치, 속도)
- R: 제어 노력 가중 (토크)

## 4. 비선형 최적 제어

### 4.1 반복 LQR (iLQR)

비선형 시스템을 선형화하여 반복적으로 해결:

**전진 패스**: 명목 궤적 계산
$$\mathbf{x}_{k+1} = \mathbf{f}(\mathbf{x}_k, \mathbf{u}_k)$$

**후진 패스**: 국소 선형화 및 LQR 해법
$$\mathbf{f}_\mathbf{x} = \frac{\partial \mathbf{f}}{\partial \mathbf{x}}, \quad \mathbf{f}_\mathbf{u} = \frac{\partial \mathbf{f}}{\partial \mathbf{u}}$$

**제어 법칙**:
$$\mathbf{u} = \mathbf{u}^* + \mathbf{K}(\mathbf{x} - \mathbf{x}^*) + \mathbf{k}$$

### 4.2 미분 동적 계획법 (DDP)

**2차 근사 가치 함수**:
$$V(\mathbf{x}) = \frac{1}{2}(\mathbf{x} - \mathbf{x}^*)^T \mathbf{V}_{\mathbf{x}\mathbf{x}} (\mathbf{x} - \mathbf{x}^*) + \mathbf{V}_\mathbf{x}^T(\mathbf{x} - \mathbf{x}^*) + V^*$$

**Q-함수 근사**:
$$Q(\mathbf{x}, \mathbf{u}) = L(\mathbf{x}, \mathbf{u}) + V(\mathbf{f}(\mathbf{x}, \mathbf{u}))$$

**최적 제어**: $\mathbf{u}^* = -\mathbf{Q}_{\mathbf{u}\mathbf{u}}^{-1}\mathbf{Q}_\mathbf{u}$

### 4.3 직접 법 (Direct Methods)

**궤적 이산화**: 연속 문제를 이산 최적화 문제로 변환

**콜로케이션 방법**:
- 사다리꼴 법칙
- 에르미트-심슨 법칙
- 가우스 구적법

**슈팅 방법**: 초기값 문제로 변환

## 5. 로봇 궤적 최적화

### 5.1 최소 시간 궤적

**목적 함수**: $J = t_f$ (종료 시간 최소화)

**제약 조건**:
- 동역학: $\mathbf{M}(\mathbf{q})\ddot{\mathbf{q}} + \mathbf{h}(\mathbf{q}, \dot{\mathbf{q}}) = \boldsymbol{\tau}$
- 토크 한계: $|\tau_i| \leq \tau_{max,i}$
- 속도 한계: $|\dot{q}_i| \leq \dot{q}_{max,i}$

### 5.2 최소 에너지 궤적

**목적 함수**: $J = \int_0^{t_f} \boldsymbol{\tau}^T\boldsymbol{\tau} dt$

**변형**:
- 전력 최소화: $\int_0^{t_f} \boldsymbol{\tau}^T\dot{\mathbf{q}} dt$
- 가중 에너지: $\int_0^{t_f} \boldsymbol{\tau}^T\mathbf{W}\boldsymbol{\tau} dt$

### 5.3 최소 저크 궤적

**목적 함수**: $J = \int_0^{t_f} \|\dddot{\mathbf{q}}\|^2 dt$

**장점**: 부드러운 궤적, 진동 최소화

## 6. 구현 고려사항

### 6.1 수치 최적화

**그래디언트 기반 방법**:
- 준뉴턴 방법 (BFGS, L-BFGS)
- 켤레 그래디언트 방법
- 신뢰 영역 방법

**그래디언트 프리 방법**:
- 유전 알고리즘
- 입자 군집 최적화
- 시뮬레이티드 어닐링

### 6.2 실시간 최적화

**모델 예측 제어**: 후퇴 지평선에서 반복 해결
**웜 스타트**: 이전 해를 초기값으로 사용
**병렬 계산**: GPU 활용한 고속 계산

### 6.3 수치 안정성

**정규화**: 조건수 개선
**스케일링**: 변수 정규화
**수렴 기준**: 적절한 허용 오차 설정

## 7. 장단점 분석

### 7.1 장점

1. **최적성**: 수학적으로 보장된 최적 해
2. **체계성**: 다양한 목적 함수 적용 가능
3. **제약 처리**: 물리적 제약 자연스럽게 고려
4. **이론적 기반**: 확립된 수학적 이론
5. **다목적 최적화**: 여러 목표 동시 고려

### 7.2 단점

1. **계산 복잡성**: 높은 계산 부담
2. **국소 최적해**: 전역 최적해 보장 어려움
3. **모델 의존성**: 정확한 모델 필요
4. **실시간 제한**: 실시간 적용 어려움
5. **튜닝 복잡성**: 가중 행렬 설계 어려움

## 8. 최신 동향

### 8.1 기계학습과의 융합
- 강화학습 기반 최적 제어
- 신경망을 이용한 가치 함수 근사
- 모델 학습과 제어 최적화 통합

### 8.2 분산 최적화
- 다중 에이전트 시스템
- 합의 기반 최적화
- 클라우드 기반 계산

### 8.3 강인 최적 제어
- 불확실성을 고려한 최적화
- 확률적 최적 제어
- 적응적 최적 제어

### 8.4 실시간 최적화
- 임베디드 최적화
- 근사 동적 계획법
- 학습 기반 웜 스타트

## 9. 관련 텍스트북 및 참고문헌

### 주요 텍스트북

1. **Kirk, D. E. (2004)**. "Optimal Control Theory: An Introduction". Dover Publications.
   - 최적 제어 이론의 고전적 명저
   - 변분법부터 동적 계획법까지 포괄

2. **Lewis, F. L., Vrabie, D., & Syrmos, V. L. (2012)**. "Optimal Control" (3rd Edition). John Wiley & Sons.
   - 현대적 접근법과 응용
   - 적응 동적 계획법 포함

3. **Bryson, A. E., & Ho, Y. C. (1975)**. "Applied Optimal Control". Taylor & Francis.
   - 응용 최적 제어의 고전
   - 실제 문제 해결 중심

4. **Bertsekas, D. P. (2017)**. "Dynamic Programming and Optimal Control" (4th Edition). Athena Scientific.
   - 동적 계획법의 권위서
   - 근사 동적 계획법까지 다룸

### 로봇 응용 전문서

1. **Verscheure, D., Demeulenaere, B., Swevers, J., De Schutter, J., & Diehl, M. (2009)**. "Time-Optimal Path Tracking for Robots: A Convex Optimization Approach". IEEE Transactions on Automatic Control.
   - 로봇 궤적 최적화의 대표 논문

2. **Ratliff, N., Zucker, M., Bagnell, J. A., & Srinivasa, S. (2009)**. "CHOMP: Gradient Optimization Techniques for Efficient Motion Planning". ICRA.
   - 기하급수 최적화 기반 경로 계획

3. **Todorov, E., & Li, W. (2005)**. "A Generalized Iterative LQG Method for Locally-Optimal Feedback Control of Constrained Nonlinear Stochastic Systems". ACC.
   - iLQG의 확률적 확장

### 최신 연구 동향
- **Amos, B., & Kolter, J. Z. (2017)**. "OptNet: Differentiable Optimization as a Layer in Neural Networks". ICML.
- **Chen, R. T. Q., Rubanova, Y., Bettencourt, J., & Duvenaud, D. (2018)**. "Neural Ordinary Differential Equations". NeurIPS.

이 문서는 Kirk의 "Optimal Control Theory"와 Lewis 등의 "Optimal Control"을 주요 참고문헌으로 하여 작성되었습니다.
