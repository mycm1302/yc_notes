# 센서융합

> 상위: [[센서시스템]]

센서융합은 다중 센서의 정보를 통합하여 단일 센서로는 얻을 수 없는 신뢰성과 정확도를 제공하는 핵심 기술입니다.

## 📊 기본 개념

### 정의
센서융합(Sensor Fusion)은 여러 센서로부터 얻은 데이터를 수학적 알고리즘을 통해 결합하여, 개별 센서보다 더 정확하고 완전하며 신뢰할 수 있는 정보를 생성하는 과정입니다.

### 융합의 필요성
- **신뢰성**: 센서 고장 시 대체 정보 제공
- **정확도**: 노이즈 감소 및 정밀도 향상  
- **완전성**: 부족한 정보 상호 보완
- **견고성**: 환경 변화에 대한 적응력 증대

---

## 🔧 융합 아키텍처

### 저수준 융합 (Low-Level)
- **데이터 수준**: 원시 센서 데이터 직접 융합
- **특징**:
  - 최대 정보 보존
  - 높은 계산 복잡도
  - 센서 간 동기화 필요
- **예시**: 스테레오 카메라의 픽셀 수준 융합

### 중수준 융합 (Mid-Level)  
- **특징 수준**: 추출된 특징 정보 융합
- **특징**:
  - 계산 효율성 향상
  - 의미 있는 정보 결합
  - 부분적 정보 손실
- **예시**: 라이다 포인트와 카메라 특징점 융합

### 고수준 융합 (High-Level)
- **결정 수준**: 각 센서의 판단 결과 융합
- **특징**:
  - 가장 간단한 구현
  - 센서 독립성 높음
  - 정보 손실 가능성
- **예시**: 다중 분류기 앙상블

---

## 🧮 융합 알고리즘

### 칼만 필터 (Kalman Filter)
- **원리**: 베이지안 추정 기반 최적 필터
- **특징**:
  - 선형 시스템에 최적
  - 가우시안 노이즈 가정
  - 실시간 처리 가능
- **확장**: EKF, UKF, 파티클 필터

```
예측 단계: x̂(k|k-1) = Fx̂(k-1|k-1) + Bu(k)
갱신 단계: x̂(k|k) = x̂(k|k-1) + K(k)[z(k) - Hx̂(k|k-1)]
```

### 확장 칼만 필터 (EKF)
- **적용**: 비선형 시스템
- **원리**: 야코비안을 통한 선형화
- **응용**: 로봇 위치 추정, SLAM
- **한계**: 높은 비선형성에서 발산 가능

### 무향 칼만 필터 (UKF)  
- **원리**: 시그마 포인트를 통한 비선형 처리
- **장점**: 야코비안 계산 불필요
- **특징**: EKF보다 정확한 비선형 근사
- **응용**: IMU/GPS 융합, 자세 추정

### 파티클 필터
- **원리**: 몬테카를로 방법 기반
- **특징**:
  - 비가우시안 분포 처리
  - 다중 가설 추적
  - 계산 집약적
- **응용**: 로봇 위치 추정, 다중 객체 추적

---

## 🤖 로봇공학 응용

### IMU/GPS 융합
- **목적**: 정확한 위치 및 자세 추정
- **장점**: GPS 신호 차단 시에도 연속 추정
- **알고리즘**: EKF, UKF 기반 INS
- **응용**: 드론, 자율주행차, 이동로봇

### 라이다/카메라 융합
- **목적**: 3D 환경 인식 향상
- **장점**: 
  - 색상 정보 + 정확한 거리
  - 다양한 환경 조건 대응
- **방법**: 포인트 클라우드에 색상 투영
- **응용**: 자율주행, 3D 매핑

### 멀티모달 SLAM
- **센서**: 라이다 + 카메라 + IMU
- **융합**: 특징점 기반 백엔드 최적화
- **장점**: 
  - 높은 정확도
  - 루프 클로저 향상
  - 환경 변화 적응
- **예시**: ORB-SLAM3, VINS-Fusion

---

## 📐 성능 평가

### 정확도 지표
- **RMSE**: 추정 오차의 제곱근 평균
- **절대 오차**: |추정값 - 실제값|
- **상대 오차**: 오차/실제값 × 100%

### 신뢰성 지표  
- **가용성**: 정상 동작 시간 비율
- **무결성**: 오차 한계 내 유지
- **연속성**: 서비스 중단 없음

### 실시간 성능
- **지연 시간**: 센서 입력 ~ 융합 출력
- **처리 속도**: 초당 융합 횟수
- **메모리 사용량**: 알고리즘 효율성

---

## 🔄 융합 기법

### 가중 평균 (Weighted Average)
```
x_fused = Σ(wi × xi) / Σwi
```
- **가중치**: 센서 신뢰도 기반
- **장점**: 간단한 구현
- **응용**: 다중 GPS 수신기

### 데이터 연관 (Data Association)
- **목적**: 서로 다른 센서의 같은 객체 매칭
- **알고리즘**: 
  - 최근접 이웃 (NN)
  - 전역 최근접 이웃 (GNN)
  - 확률적 데이터 연관 (PDA)

### 상태 추정
- **다중 모델**: IMM(Interacting Multiple Model)
- **적응적 필터**: 노이즈 특성 실시간 조정
- **견고한 추정**: 이상치 제거

---

## 🌟 최신 동향

### 딥러닝 기반 융합
- **신경망**: CNN, RNN, Transformer
- **학습**: 센서 간 상관관계 자동 학습
- **장점**: 복잡한 비선형 관계 모델링
- **응용**: 멀티모달 인식, 예측

### 엣지 AI 융합
- **실시간**: 센서 근처에서 즉시 처리
- **저지연**: 네트워크 전송 최소화
- **효율성**: 전력 소모 최적화

### 연합 학습 (Federated Learning)
- **분산 융합**: 다중 로봇 간 정보 공유
- **프라이버시**: 원시 데이터 비공개
- **협력**: 집단 지능 구현

---

## 💻 구현 예제

### IMU/엔코더 융합 (상보 필터)
```cpp
float alpha = 0.98;
float dt = 0.01;

// 각속도 적분 (고주파)
angle_gyro += gyro_rate * dt;

// 가속도계 각도 (저주파)  
angle_accel = atan2(accel_y, accel_z);

// 상보 융합
angle_fused = alpha * angle_gyro + (1-alpha) * angle_accel;
```

### 다중 센서 위치 추정
```python
# EKF 예측 단계
x_pred = F @ x_est + B @ u
P_pred = F @ P_est @ F.T + Q

# 각 센서별 갱신
for sensor in sensors:
    if sensor.available():
        # 갱신 단계
        K = P_pred @ H.T @ inv(H @ P_pred @ H.T + R)
        x_est = x_pred + K @ (z - H @ x_pred)  
        P_est = (I - K @ H) @ P_pred
```

---

## 🔗 상용 솔루션

### 하드웨어 플랫폼
- **NVIDIA Jetson**: GPU 가속 융합 처리
- **Intel RealSense**: 비전 + 깊이 통합
- **Xsens MTi**: IMU/GPS 융합 모듈

### 소프트웨어 프레임워크
- **ROS**: sensor_msgs, geometry_msgs
- **OpenCV**: 이미지 기반 융합
- **PCL**: 포인트 클라우드 융합
- **GTSAM**: 그래프 기반 SLAM

### 상용 제품
- **VectorNav VN-300**: IMU/GPS 통합
- **Advanced Navigation**: 멀티센서 INS
- **Bosch**: 자동차용 센서 융합

---

## 📊 응용 사례

### 자율주행
- **센서**: 라이다 + 카메라 + 레이더 + GPS + IMU
- **융합**: 객체 검출, 위치 추정, 경로 계획
- **신뢰성**: 안전 임계 응용

### 드론 내비게이션  
- **센서**: IMU + GPS + 바로미터 + 광류
- **융합**: 안정화 제어, 자율 비행
- **응용**: 배송, 측량, 감시

### 산업 로봇
- **센서**: 엔코더 + IMU + 힘토크 + 비전
- **융합**: 정밀 제어, 안전 감시
- **응용**: 조립, 용접, 도장

---

## 📚 참고 문헌

1. **IEEE 학술 논문**:
   - ["Multiple sensor fusion for mobile robot localization using Extended Kalman Filter"](https://ieeexplore.ieee.org/document/7373480/) - IEEE 2015
   - ["A robust and modular multi-sensor fusion approach applied to MAV navigation"](https://ieeexplore.ieee.org/document/6696917/) - IEEE 2013
   - ["Sensor fusion for prediction of orientation using Kalman filter"](https://ieeexplore.ieee.org/document/7011716/) - IEEE 2014

2. **최신 연구**:
   - ["Application of multi-sensor fusion localization algorithm based on recurrent neural networks"](https://www.nature.com/articles/s41598-025-90492-4) - Nature 2025
   - ["A Loosely Coupled Extended Kalman Filter Algorithm for Agricultural Scene-Based Multi-Sensor Fusion"](https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2022.849260/full) - Frontiers 2022

3. **기술 리뷰**:
   - ["Sensor-Fusion Based Navigation for Autonomous Mobile Robot"](https://pmc.ncbi.nlm.nih.gov/articles/PMC11861736/) - PMC 2024
   - ["A fault-tolerant sensor fusion in mobile robots using multiple model Kalman filters"](https://www.sciencedirect.com/science/article/abs/pii/S0921889022002329) - ScienceDirect 2022

4. **교육 자료**:
   - ["Sensor Fusion With Kalman Filter"](https://medium.com/@satya15july_11937/sensor-fusion-with-kalman-filter-c648d6ec2ec2) - Medium 2023
   - ["Multi-Sensor Integration: Techniques & Examples"](https://www.vaia.com/en-us/explanations/engineering/robotics-engineering/multi-sensor-integration/)
   - [Springer: "Multisensor Data Fusion"](https://link.springer.com/chapter/10.1007/978-3-540-30301-5_26)

---

## 🔗 연결 분야
- 상위: [[센서시스템]]
- 기술: [[칼만필터]], [[베이지안추론]]
- 응용: [[SLAM]], [[상태추정]]
- 센서: [[IMU]], [[라이다]], [[비전센서]]